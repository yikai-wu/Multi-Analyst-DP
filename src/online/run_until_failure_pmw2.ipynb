{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f52b58df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from src.hdmm.error import expected_error, strategy_supports_workload\n",
    "from src.hdmm.matrix import EkteloMatrix\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from src.hdmm.workload import AllRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cec2d91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', '{:0.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64eae0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBounds(df):\n",
    "    \"\"\"\n",
    "    Returns [upper bound error, lower bound error]\n",
    "    \"\"\"\n",
    "    return [df.abs_error.min(), df.abs_error.max()]\n",
    "\n",
    "def getAverageError(df):\n",
    "    \"\"\"\n",
    "    Returns average error across all queries\n",
    "    \"\"\"\n",
    "    return df.abs_error.sum() / len(df)\n",
    "\n",
    "def printBoundsAndAvgError(df):\n",
    "    print(f'Average error is {getAverageError(df)}. Lower bound is {getBounds(df)[0]} and upper bound is {getBounds(df)[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77bd3f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmw2(workload, x, T, eps=0.01, k=0, analyst_labels = [], \n",
    "         show_messages=True, to_return='pd', show_plot=False, show_failure_step=True):\n",
    "    \"\"\"\n",
    "    Implement Private Multiplicative Weights Mechanism (PMW) on a workload of\n",
    "    linear queries. \n",
    "\n",
    "    Algorithm Parameters: \n",
    "    - workload = workload of queries (M x k numpy array)\n",
    "    - x = true database (M x 1 numpy array)\n",
    "    - T = update threshold\n",
    "    - eps = privacy budget\n",
    "    - k = number of update steps PER ANALYST\n",
    "    - analyst_labels = list of analyst names corresponding to each query in the workload\n",
    "    \n",
    "    Output Controls: \n",
    "    - show_messages argument determines whether the function will print information such as \n",
    "    error scale, threshold, update steps used, etc.\n",
    "    - to_return argument determines what the function will return. \n",
    "        - if 'pd', pmw() returns pandas df with test data for each \n",
    "        query in the workload(showing query, d_t_hat, updated, algo_ans, real_ans, \n",
    "        abs_error, rel_error). \n",
    "        - if 'update_count', pmw() returns the update count for the total\n",
    "        amount of queries.\n",
    "    - show_plot - T/F whether the function will display a plot\n",
    "    - show_failure_step - T/F whether function prints what step failure mode is reached\n",
    "    \"\"\" \n",
    "    \n",
    "    update_steps = {}\n",
    "    for analyst in list(set(analyst_labels)): \n",
    "        update_steps[analyst] = k # each analyst starts with k update steps\n",
    "    \n",
    "    # initialize constants\n",
    "    m = x.size  # database len\n",
    "    n = x.sum()\n",
    "    eta = (math.log(m, np.e) ** (1 / 4)) / (math.sqrt(n))\n",
    "    delta = 1 / (n * math.log(n, np.e))\n",
    "    x_norm = x / np.sum(x)\n",
    "    \n",
    "    # initialize synthetic databases at time 0 (prior to any queries)\n",
    "    x_t = np.ones(m) / m\n",
    "    y_t = np.ones(m) / m\n",
    "\n",
    "    # initialize tracker lists to construct pandas dataframe at the end \n",
    "    x_list = [x_t] # create a list of x_t synthetic database at every time step\n",
    "    update_list = []\n",
    "    update_count = 0\n",
    "    pmw_answers = []\n",
    "    update_times = [] # record times that database is updated\n",
    "    d_t_hat_list = []\n",
    "    \n",
    "    def lazy_round():\n",
    "        \"\"\"\n",
    "        \"Lazy Round\" of querying using the stored synthetic database, x_t, in list x_list.\n",
    "        \n",
    "        We call this the lazy round because it is contrasted with the updated step where we update the \n",
    "        sythetic database and answer the query using the real database.\n",
    "        \"\"\"\n",
    "        update_list.append('no')\n",
    "        pmw_answers.append(np.dot(query, x_list[time]))\n",
    "        x_list.append(x_list[time].round(3))\n",
    "    \n",
    "    # inititate first instance of SVT with half the budget and k updates; will be reset in the main loop\n",
    "    SVTtrigger = False \n",
    "    SVTepsilon1 = ((eps/2)/2)\n",
    "    SVTepsilon2 = ((eps/2)/2)\n",
    "    rho = np.random.laplace(loc=0, scale=(1/SVTepsilon1), size=1)[0]\n",
    "    \n",
    "    for time, query in enumerate(workload):\n",
    "        \n",
    "        analyst = analyst_labels[time]\n",
    "        \n",
    "        # Do one round of sparse vector technique \n",
    "        \n",
    "        # Compute noisy answer by adding Laplacian noise\n",
    "        a_t = np.random.laplace(loc=0, scale=(2*k/SVTepsilon2), size=1)[0]\n",
    "        a_t_hat = (np.dot(query, x_norm)*n ) + a_t\n",
    "\n",
    "        # Difference between noisy and maintained histogram answer\n",
    "        d_t_hat = a_t_hat - (n*np.dot(query, x_list[time]))\n",
    "        \n",
    "        # Lazy round: use synthetic base to answer the query\n",
    "        if (abs(d_t_hat) <= T + rho):\n",
    "            d_t_hat_list.append(d_t_hat)\n",
    "            lazy_round()\n",
    "            continue\n",
    "\n",
    "        # update round: update histogram and return noisy answer\n",
    "        else:\n",
    "            #make a new noisy query answer using some of the leftover budget\n",
    "            a_t = np.random.laplace(loc=0, scale=(2*k/eps), size=1)[0]\n",
    "            a_t_hat = (np.dot(query, x_norm)*n ) + a_t\n",
    "            d_t_hat = a_t_hat - (n*np.dot(query, x_list[time]))\n",
    "            d_t_hat_list.append(d_t_hat)\n",
    "            update_times.append(time)\n",
    "            \n",
    "            # step a\n",
    "            if d_t_hat < 0:\n",
    "                r_t = query\n",
    "            else:\n",
    "                r_t = np.ones(m) - query\n",
    "            for i, v in enumerate(y_t):\n",
    "                y_t[i] = x_list[time][i] * math.exp((d_t_hat/(2*n)) * query[i]) * 20 # 20 is the learning rate\n",
    "            \n",
    "            # step b\n",
    "            x_t = y_t / np.sum(y_t)\n",
    "            update_count = update_list.count('yes')\n",
    "            \n",
    "            # if threshold for num updates is reached, just do a lazy round (synthetic database) answer\n",
    "            if update_steps[analyst] == 0: \n",
    "                if show_failure_step:\n",
    "                    print(f'Failure mode reached at query number {time}: {query}')\n",
    "                lazy_round()\n",
    "                \n",
    "            # if there are still update steps that the analyst can use, \n",
    "            # 1. update the synthetic database\n",
    "            # 2. answer the query using the noisy answer from the database itself \n",
    "            else: \n",
    "                x_list.append(x_t.round(3))\n",
    "                update_list.append('yes') # increment number of updates counter\n",
    "                pmw_answers.append(a_t_hat / np.sum(x))\n",
    "                update_steps[analyst] -= 1 # use one of analyst's update steps\n",
    "\n",
    "    update_count = update_list.count('yes')      \n",
    "\n",
    "    # calculate error\n",
    "    real_ans = np.matmul(workload, x_norm)\n",
    "    abs_error = np.abs(pmw_answers - real_ans)\n",
    "    rel_error = np.abs(abs_error / np.where(real_ans == 0, 0.000001,\n",
    "                                                real_ans))\n",
    "    \n",
    "    if show_messages:\n",
    "        np.set_printoptions(suppress=True)\n",
    "        \"\"\"Print inputes/outputs to analyze each query\"\"\"\n",
    "        print(f'Original database: {x}\\n')\n",
    "        print(f'Normalized database: {x_norm}\\n')\n",
    "        print(f'Updated Database = {x_t}\\n')\n",
    "        print(f'Update Count = {update_count}\\n')\n",
    "        print(f'{T=}\\n')\n",
    "        print(f'Error Scale Query Answer= {2*((2*k/eps)**2)}\\n')\n",
    "        print(f'Error Scale SVT= {2*((2*k/SVTepsilon2)**2)}\\n')\n",
    "        print(f'Update Parameter Scale = {eta}\\n')\n",
    "        print(f'{delta=}\\n')\n",
    "        \n",
    "    if show_plot: \n",
    "        plt.title('Error across queries:')\n",
    "        rel_line, = plt.plot(rel_error, label='Relative Error')\n",
    "        abs_line, = plt.plot(abs_error, label='Absolute Error')\n",
    "        for xc in update_times:\n",
    "            plt.axvline(x=xc, color='red', label='Update Times', linestyle='dashed')\n",
    "        plt.legend(handles=[abs_line,rel_line])\n",
    "        plt.xticks(range(0, len(workload), round(len(workload)/5)))\n",
    "    \n",
    "    if to_return == \"pd\":\n",
    "        # hacky fix: remove the first synthetic database to keep length of lists consistent with the\n",
    "        # other lists that comprise of the pandas dataframe\n",
    "        x_list.pop(0).tolist() \n",
    "        d = {\n",
    "            'algo_ans': pmw_answers,\n",
    "            'real_ans': real_ans.tolist(),\n",
    "            'queries': workload.tolist(), \n",
    "            'updated': update_list,\n",
    "            'abs_error': abs_error,               \n",
    "            'rel_error': rel_error,\n",
    "            'synthetic database': x_list,\n",
    "            'analyst': analyst_labels,\n",
    "            'd_t_hat': d_t_hat_list, \n",
    "\n",
    "             }\n",
    "        test_data = pd.DataFrame(data=d)\n",
    "        test_data = test_data.round(3)\n",
    "        return test_data\n",
    "    \n",
    "    # return dictionary of absolute errors\n",
    "    if to_return == \"error\":\n",
    "        d = {'analyst': analyst_labels,\n",
    "             'abs_error': abs_error,               \n",
    "             'rel_error': rel_error,}\n",
    "        data = pd.DataFrame(data=d)\n",
    "        data = data.round(3)\n",
    "        \n",
    "        analyst_error = {}\n",
    "        for analyst in list(set(analyst_labels)):\n",
    "            analyst_error[analyst] = data[data.analyst==analyst]['abs_error'].sum()\n",
    "        return analyst_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea17ca88",
   "metadata": {},
   "source": [
    "### Initializing workloads and databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2a073ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_small = np.array([20, 160, 20, 20, 20, 160, 20, 20])\n",
    "normalized = x_small / x_small.sum()\n",
    "m = x_small.size  # database len\n",
    "n = x_small.sum()\n",
    "#print(f'the threshold for failure is {n * math.log(m, np.e) ** (1 / 2)}')\n",
    "\n",
    "random_array = np.random.randint(2, size=(500,4))\n",
    "zero_array = np.zeros((500,4))\n",
    "alice = np.hstack((random_array, zero_array))\n",
    "bob = np.hstack((zero_array, random_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150ca2fd",
   "metadata": {},
   "source": [
    "We've shown that Alice can use up all the privacy budget. \n",
    "\n",
    "Next, let's take some of the basic adaptations of pmw and see if we can get the same effects to happen or a similar effect were people get similar results indpenedently\n",
    "\n",
    "### To Dos: \n",
    "\n",
    "Instead of having a communal pool of update steps we can do, split the amount of update steps evenly across all analysts. If your update steps are not a multiple of the analysts, you can change the number of update steps.  \n",
    "\n",
    "Look for the same kind of violation where either Bob or Alice will have more overall error in the joint case as opposed to the independent case.\n",
    "\n",
    "In the independent state, you can use the existing pmw algorihtm.\n",
    "\n",
    "Suggestion: When you split it to their individual settings, give them the same amount of update steps that they would've gotten in the group. \n",
    "\n",
    "Individually - 1 ep, 5 k. together - 2 ep, 10k. \n",
    "\n",
    "### Experiments: \n",
    "Try original pmw, adapted w equal update steps pmw, individual: \n",
    "1. [done] A and B query disjoint sections\n",
    "2. [done] A queries the entire dataset except for last index. B queries entire dataset, last index inclusive. \n",
    "3. [done] A asks singleton, B asks all range queries\n",
    "4. [if time] Is total error the right metric? Context: You might run into a case where you get flat error across all of your queries. You may get a lot worse error on one specific query, but the overall error is better. Now Alice and Bob care about the same data. Alice eats all the budget (entire database except for last). Bob cares about entire database, but his queries about the last index has higher error. \n",
    "    \n",
    "    \n",
    "Scenarios to look for: \n",
    "1. Regular pmw performs poorly, but adapted pmw works well. (probably in disjoint setting)\n",
    "2. Scenarios where regular AND adapted pmw perform poorly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36962c66",
   "metadata": {},
   "source": [
    "## Scenario 1: Disjoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ced25535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alice_first</th>\n",
       "      <th>individual</th>\n",
       "      <th>bob_first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alice</th>\n",
       "      <td>1.54</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bob</th>\n",
       "      <td>1.57</td>\n",
       "      <td>2.29</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       alice_first  individual  bob_first\n",
       "Alice         1.54        2.30       1.57\n",
       "Bob           1.57        2.29       1.56"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize\n",
    "s1random_array = np.random.randint(2, size=(25,4))\n",
    "s1zero_array = np.zeros((25,4))\n",
    "s1alice_q = np.hstack((s1random_array, s1zero_array))\n",
    "s1bob_q = np.hstack((s1zero_array, s1random_array))\n",
    "\n",
    "s1combined_list = []\n",
    "s1bobfirst_list = []\n",
    "s1individual_list = []\n",
    "\n",
    "for i in range(1000):\n",
    "    # combined\n",
    "    s1combined = pmw2(workload=np.vstack((s1alice_q, s1bob_q)), x=x_small, eps=2, T=40, k=10,  \n",
    "                                 analyst_labels=['Alice'] * 25 + ['Bob'] * 25, \n",
    "                                 to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s1combined_list.append(s1combined)\n",
    "    \n",
    "    s1bobfirst = pmw2(workload=np.vstack((s1bob_q, s1alice_q)), x=x_small, eps=2, T=40, k=10,  \n",
    "                                 analyst_labels=['Bob'] * 25 + ['Alice'] * 25, \n",
    "                                 to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s1bobfirst_list.append(s1bobfirst)\n",
    "    \n",
    "    # individual\n",
    "    s1a = pmw2(workload=s1alice_q, x=x_small, eps=1, T=40, k=5,\n",
    "               analyst_labels=['Alice'] * 25, \n",
    "               to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s1b = pmw2(workload=s1bob_q, x=x_small, eps=1, T=40, k=5,\n",
    "               analyst_labels=['Bob'] * 25, \n",
    "               to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s1individual = {**s1a, **s1b}\n",
    "    s1individual_list.append(s1individual)\n",
    "    \n",
    "# find mean over multiple trials\n",
    "s1combined_average = dict(pd.DataFrame(s1combined_list).mean())\n",
    "s1bobfirst_average = dict(pd.DataFrame(s1bobfirst_list).mean())\n",
    "s1individual_average = dict(pd.DataFrame(s1individual_list).mean())\n",
    "\n",
    "d = {'alice_first': s1combined_average, 'individual': s1individual_average, 'bob_first': s1bobfirst_average}\n",
    "df = pd.DataFrame(data=d).sort_index()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a855c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original database: [ 20 160  20  20  20 160  20  20]\n",
      "\n",
      "Normalized database: [0.04545455 0.36363636 0.04545455 0.04545455 0.04545455 0.36363636\n",
      " 0.04545455 0.04545455]\n",
      "\n",
      "Updated Database = [0.12091734 0.15275676 0.1272973  0.12322378 0.11895121 0.11895121\n",
      " 0.11895121 0.11895121]\n",
      "\n",
      "Update Count = 5\n",
      "\n",
      "T=40\n",
      "\n",
      "Error Scale Query Answer= 200.0\n",
      "\n",
      "Error Scale SVT= 3200.0\n",
      "\n",
      "Update Parameter Scale = 0.05724800287506827\n",
      "\n",
      "delta=0.0003733877750853085\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo_ans</th>\n",
       "      <th>real_ans</th>\n",
       "      <th>queries</th>\n",
       "      <th>updated</th>\n",
       "      <th>abs_error</th>\n",
       "      <th>rel_error</th>\n",
       "      <th>synthetic database</th>\n",
       "      <th>analyst</th>\n",
       "      <th>d_t_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.09</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.75</td>\n",
       "      <td>[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-10.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.46</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.20</td>\n",
       "      <td>[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-4.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.36</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.06</td>\n",
       "      <td>[0.123, 0.14, 0.123, 0.123, 0.123, 0.123, 0.12...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>114.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.46</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.15</td>\n",
       "      <td>[0.123, 0.14, 0.123, 0.123, 0.123, 0.123, 0.12...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>20.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.46</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.125, 0.143, 0.125, 0.121, 0.121, 0.121, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>28.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.41</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.10</td>\n",
       "      <td>[0.13, 0.149, 0.124, 0.12, 0.12, 0.12, 0.12, 0...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>43.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.93</td>\n",
       "      <td>[0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-55.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.09</td>\n",
       "      <td>[1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.68</td>\n",
       "      <td>[0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-26.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.09</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.71</td>\n",
       "      <td>[0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-33.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.41</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.33</td>\n",
       "      <td>[0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>63.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.14</td>\n",
       "      <td>[1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>[0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-119.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.46</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.13</td>\n",
       "      <td>[0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>25.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.36</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.59</td>\n",
       "      <td>[0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-27.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.41</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.33</td>\n",
       "      <td>[0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>6.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.66</td>\n",
       "      <td>[0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-19.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>10.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.46</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>[0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>22.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.09</td>\n",
       "      <td>[1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.68</td>\n",
       "      <td>[0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-65.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.46</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.13</td>\n",
       "      <td>[0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-9.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.41</td>\n",
       "      <td>[0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.33</td>\n",
       "      <td>[0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>69.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.41</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.33</td>\n",
       "      <td>[0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>68.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.71</td>\n",
       "      <td>[0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-35.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.66</td>\n",
       "      <td>[0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>19.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.41</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.34</td>\n",
       "      <td>[0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>28.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.46</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.13</td>\n",
       "      <td>[0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>31.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    algo_ans  real_ans                                   queries updated  \\\n",
       "0       0.25      0.09  [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "1       0.36      0.46  [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]     yes   \n",
       "2       0.39      0.36  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]     yes   \n",
       "3       0.39      0.46  [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "4       0.45      0.46  [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]     yes   \n",
       "5       0.37      0.41  [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]     yes   \n",
       "6       0.00      0.04  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]     yes   \n",
       "7       0.24      0.09  [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "8       0.25      0.09  [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "9       0.27      0.41  [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "10      0.37      0.14  [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "11      0.39      0.46  [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "12      0.15      0.36  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "13      0.27      0.41  [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "14      0.12      0.04  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "15      0.00      0.00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "16      0.40      0.46  [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "17      0.24      0.09  [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "18      0.39      0.46  [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "19      0.28      0.41  [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "20      0.27      0.41  [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "21      0.12      0.04  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "22      0.12      0.04  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "23      0.27      0.41  [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "24      0.40      0.46  [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "\n",
       "    abs_error  rel_error                                 synthetic database  \\\n",
       "0        0.16       1.75  [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.1...   \n",
       "1        0.09       0.20  [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.1...   \n",
       "2        0.02       0.06  [0.123, 0.14, 0.123, 0.123, 0.123, 0.123, 0.12...   \n",
       "3        0.07       0.15  [0.123, 0.14, 0.123, 0.123, 0.123, 0.123, 0.12...   \n",
       "4        0.00       0.01  [0.125, 0.143, 0.125, 0.121, 0.121, 0.121, 0.1...   \n",
       "5        0.04       0.10  [0.13, 0.149, 0.124, 0.12, 0.12, 0.12, 0.12, 0...   \n",
       "6        0.04       0.93  [0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...   \n",
       "7        0.15       1.68  [0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...   \n",
       "8        0.15       1.71  [0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...   \n",
       "9        0.14       0.33  [0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...   \n",
       "10       0.23       1.71  [0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...   \n",
       "11       0.06       0.13  [0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...   \n",
       "12       0.21       0.59  [0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...   \n",
       "13       0.14       0.33  [0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...   \n",
       "14       0.08       1.66  [0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...   \n",
       "15       0.00       0.00  [0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...   \n",
       "16       0.06       0.12  [0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...   \n",
       "17       0.15       1.68  [0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...   \n",
       "18       0.06       0.13  [0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...   \n",
       "19       0.13       0.33  [0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...   \n",
       "20       0.14       0.33  [0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...   \n",
       "21       0.08       1.71  [0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...   \n",
       "22       0.08       1.66  [0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...   \n",
       "23       0.14       0.34  [0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...   \n",
       "24       0.06       0.13  [0.123, 0.15, 0.125, 0.121, 0.121, 0.121, 0.12...   \n",
       "\n",
       "   analyst  d_t_hat  \n",
       "0    Alice   -10.68  \n",
       "1    Alice    -4.95  \n",
       "2    Alice   114.85  \n",
       "3    Alice    20.62  \n",
       "4    Alice    28.24  \n",
       "5    Alice    43.57  \n",
       "6    Alice   -55.86  \n",
       "7    Alice   -26.89  \n",
       "8    Alice   -33.99  \n",
       "9    Alice    63.77  \n",
       "10   Alice  -119.20  \n",
       "11   Alice    25.27  \n",
       "12   Alice   -27.00  \n",
       "13   Alice     6.18  \n",
       "14   Alice   -19.92  \n",
       "15   Alice    10.98  \n",
       "16   Alice    22.74  \n",
       "17   Alice   -65.57  \n",
       "18   Alice    -9.70  \n",
       "19   Alice    69.01  \n",
       "20   Alice    68.06  \n",
       "21   Alice   -35.84  \n",
       "22   Alice    19.20  \n",
       "23   Alice    28.05  \n",
       "24   Alice    31.05  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmw2(workload=s1alice_q, x=x_small, eps=1, T=40, k=5,\n",
    "               analyst_labels=['Alice'] * 25, \n",
    "               show_plot=False, show_messages=True, show_failure_step=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36abc58",
   "metadata": {},
   "source": [
    "Bob always receives more error in the combined setting than in the individual setting.\n",
    "\n",
    "Questions: \n",
    "\n",
    "1. Why does Bob always receives more error than Alice in the individual setting if their queries are not related? I would expect instead that their individual error would be very similar. **Bob's spike is larger**\n",
    "    \n",
    "2. Alice receives substantially more error in the individual setting than the combined setting. Is this supposed to happen? Although she receives less update steps in the individual setting, shouldn't the smaller epsilon value in the inidivual case counteract this effect? **Alice gets more update steps in the combined setting (eats Bob's)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b47e834",
   "metadata": {},
   "outputs": [],
   "source": [
    "printBoundsAndAvgError(pmw2(workload=np.vstack((s1alice_q, s1bob_q)), x=x_small, eps=2, T=40, k=10,  \n",
    "                                 analyst_labels=['Alice'] * 25 + ['Bob'] * 25, \n",
    "                                 to_return='pd', show_plot=False, show_messages=False, show_failure_step=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ac519d",
   "metadata": {},
   "source": [
    "We measure average error becauase we want to think about infinite query sequences - the types of sequences that PMW are very good at. Average error is better for longer query sequences. PMW is designed to make guarantees on average error. The error will be less than $\\alpha$ with some probability of failure $\\beta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d52e699",
   "metadata": {},
   "source": [
    "# Scenario 2: Last Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02ad865",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2combined_list = []\n",
    "s2individual_list = []\n",
    "s2bobfirst_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    # combined\n",
    "    s2alice_q = np.hstack((np.random.randint(2, size=(25,7)), np.zeros((25,1))))\n",
    "    s2bob_q = np.random.randint(2, size=(25,8))\n",
    "\n",
    "    s2combined = pmw2(workload=np.vstack((s2alice_q, s2bob_q)), x=x_small, eps=2, T=40, k=10,  \n",
    "                                 analyst_labels=['Alice'] * 25 + ['Bob'] * 25, \n",
    "                                 to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s2combined_list.append(s2combined)\n",
    "\n",
    "    \n",
    "    s2bobfirst = pmw2(workload=np.vstack((s2bob_q, s2alice_q)), x=x_small, eps=2, T=40, k=10,  \n",
    "                                 analyst_labels= ['Bob'] * 25 + ['Alice'] * 25, \n",
    "                                 to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s2bobfirst_list.append(s1bobfirst)\n",
    "    \n",
    "    # individual\n",
    "    s2a = pmw2(workload=s2alice_q, x=x_small, eps=1, T=40, k=5,\n",
    "               analyst_labels=['Alice'] * 25, \n",
    "               to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s2b = pmw2(workload=s2bob_q, x=x_small, eps=1, T=40, k=5,\n",
    "               analyst_labels=['Bob'] * 25, \n",
    "               to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s2individual = {**s2a, **s2b}\n",
    "    s2individual_list.append(s2individual)\n",
    "\n",
    "# find mean over multiple trials\n",
    "s2combined_average = dict(pd.DataFrame(s2combined_list).mean())\n",
    "s2individual_average = dict(pd.DataFrame(s2individual_list).mean())\n",
    "s2bobfirst_average = dict(pd.DataFrame(s1bobfirst_list).mean())\n",
    "\n",
    "d = {'alice_first': s2combined_average, 'individual': s2individual_average, 'bob_first': s2bobfirst_average}\n",
    "df = pd.DataFrame(data=d).sort_index()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924f9750",
   "metadata": {},
   "source": [
    "all indices except last -> all indices: 1.29 difference\n",
    "all indices -> all indices except last: 1.69 difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3632f973",
   "metadata": {},
   "source": [
    "Alice is doing better than Bob in the individual and combined setting. \n",
    "\n",
    "When Bob goes first, he suffers less error than alice did when she went first. \n",
    "\n",
    "**Alice's error** in `bob_first` > **Bob's error** in `alice_first`. This makes the empirical point that if the second person queries less from the dataset than the first person, they face more error than going second if you query more from the dataset than the first person. This doesn't make sense to me. Shouldn't the second person that explores more of the dataset that has been previously unexplored experience more error than the second person in the other scenario that explores less of the dataset that had already been previous explored?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b070f1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "printBoundsAndAvgError(pmw2(workload=np.vstack((s2alice_q, s2bob_q)), x=x_small, eps=2, T=40, k=10,  \n",
    "                                 analyst_labels=['Alice'] * 25 + ['Bob'] * 25, \n",
    "                                 to_return='pd', show_plot=False, show_messages=False, show_failure_step=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04abce05",
   "metadata": {},
   "source": [
    "# Scenario 3: Incompatible Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3a6d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3combined_list = []\n",
    "s3individual_list = []\n",
    "s3bobfirst_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    lst = [[0] * 8 for i in range(36)]\n",
    "    for i in range(len(lst)):\n",
    "        lst[i][np.random.randint(0, 8)] = 1\n",
    "    s3bob_q = np.array(lst)\n",
    "    s3alice_q = AllRange(8).dense_matrix()\n",
    "\n",
    "    # combined\n",
    "    s3combined = pmw2(workload=np.vstack((s3alice_q, s3bob_q)), x=x_small, eps=2, T=40, k=10,  \n",
    "                                 analyst_labels=['Alice'] * 36 + ['Bob'] * 36, \n",
    "                                 to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s3combined_list.append(s3combined)\n",
    "    \n",
    "    \n",
    "    s3bobfirst = pmw2(workload=np.vstack((s3bob_q, s3alice_q)), x=x_small, eps=2, T=40, k=10,  \n",
    "                                 analyst_labels=['Bob'] * 36 + ['Alice'] * 36, \n",
    "                                 to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s3bobfirst_list.append(s3bobfirst)\n",
    "    \n",
    "    # individual\n",
    "    s3a = pmw2(workload=s3alice_q, x=x_small, eps=1, T=40, k=5,\n",
    "               analyst_labels=['Alice'] * 36, \n",
    "               to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s3b = pmw2(workload=s3bob_q, x=x_small, eps=1, T=40, k=5,\n",
    "               analyst_labels=['Bob'] * 36, \n",
    "               to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s3individual = {**s3a, **s3b}\n",
    "    s3individual_list.append(s3individual)\n",
    "    \n",
    "# find mean over multiple trials\n",
    "s3combined_average = dict(pd.DataFrame(s3combined_list).mean())\n",
    "s3individual_average = dict(pd.DataFrame(s3individual_list).mean())\n",
    "s3bobfirst_average = dict(pd.DataFrame(s3bobfirst_list).mean())\n",
    "\n",
    "d = {'alice_first': s3combined_average, 'individual': s3individual_average, 'bob_first': s3bobfirst_average}\n",
    "df = pd.DataFrame(data=d).sort_index()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601b2e89",
   "metadata": {},
   "source": [
    "Alice = All Range\n",
    "\n",
    "Bob = Singleton\n",
    "\n",
    "In All Range -> Singleton case, 1.22 more error for second person\n",
    "\n",
    "In Singleton -> All Range case, 0.62 more error for second person\n",
    "\n",
    "This makes sense to me because the All Range workload includes the Singleton queries, so the synthetic database had already been updated to respond to those types of queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff21a6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "printBoundsAndAvgError(pmw2(workload=np.vstack((s3alice_q, s3bob_q)), x=x_small, eps=2, T=40, k=10,  \n",
    "                                 analyst_labels=['Alice'] * 36 + ['Bob'] * 36, \n",
    "                                 to_return='pd', show_plot=False, show_messages=False, show_failure_step=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f832dd9c",
   "metadata": {},
   "source": [
    "# experiment 4: exact same workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973dc5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s4combined_list = []\n",
    "s4individual_list = []\n",
    "s4bobfirst_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    s4alice_q = np.random.randint(2, size=(25,8))\n",
    "    s4bob_q = s4alice_q\n",
    "\n",
    "    # combined\n",
    "    s4combined = pmw2(workload=np.vstack((s4alice_q, s4bob_q)), x=x_small, eps=2, T=40, k=10,  \n",
    "                                 analyst_labels=['Alice'] * 25 + ['Bob'] * 25, \n",
    "                                 to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s4combined_list.append(s4combined)\n",
    "    \n",
    "    s4bobfirst = pmw2(workload=np.vstack((s4bob_q, s4alice_q)), x=x_small, eps=2, T=40, k=10,  \n",
    "                                 analyst_labels=['Bob'] * 25 + ['Alice'] * 25, \n",
    "                                 to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s4bobfirst_list.append(s4bobfirst)\n",
    "    \n",
    "    # individual\n",
    "    s4a = pmw2(workload=s4alice_q, x=x_small, eps=1, T=40, k=5,\n",
    "               analyst_labels=['Alice'] * 25, \n",
    "               to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s4b = pmw2(workload=s4bob_q, x=x_small, eps=1, T=40, k=5,\n",
    "               analyst_labels=['Bob'] * 25, \n",
    "               to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s4individual = {**s4a, **s4b}\n",
    "    s4individual_list.append(s4individual)\n",
    "    \n",
    "# find mean over multiple trials\n",
    "s4combined_average = dict(pd.DataFrame(s4combined_list).mean())\n",
    "s4individual_average = dict(pd.DataFrame(s4individual_list).mean())\n",
    "s4bobfirst_average = dict(pd.DataFrame(s4bobfirst_list).mean())\n",
    "\n",
    "d = {'alice_first': s4combined_average, 'individual': s4individual_average, 'bob_first': s4bobfirst_average}\n",
    "df = pd.DataFrame(data=d).sort_index()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395753a8",
   "metadata": {},
   "source": [
    "Makes sense to me. We are just switching the orders in which Alice and Bob are querying, and they have the exact same queries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594131a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "printBoundsAndAvgError(pmw2(workload=np.vstack((s4alice_q, s4bob_q)), x=x_small, eps=2, T=40, k=10,  \n",
    "                                 analyst_labels=['Alice'] * 25 + ['Bob'] * 25, \n",
    "                                 to_return='pd', show_plot=False, show_messages=False, show_failure_step=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bb6d0e",
   "metadata": {},
   "source": [
    "# To Do's (10/12)\n",
    "1. [DONE] Do 1000 Trials for scenario 2 and 3\n",
    "2. [DONE] Explaining the scenarios (why we chose these scenarios)\n",
    "- Output the 3 tables. Practice explaining the tables to someone who doesn't know what's going on. \n",
    "- The general idea is that we want to show that the problem exist. These experiments show that standard online answering algorithms still have problems. \n",
    "    - experiment 1: disjoint, most adversarial setting. \n",
    "    - experiment 2: if we make a less extreme setting, alice only cares about most of the dataset, we still have this problem \n",
    "    - experiment 3: even when we use the entire database and use different types of database, we still run into this problem. Bob's workload is even embedded in Alice's workload!!\n",
    "    - experiment 4: give them the exact same things, and bob is stil worse off. \n",
    "        - opposite of the free-rider problem - some folks can freely benefit from the public road without paying for it. in this case, if Bob had better error than Alice, then it would be free-rider problem. Not only are update steps better for making ur synthetic database better, update steps are better than any synthetic answer at all\n",
    "    \n",
    "    \n",
    "    \n",
    "- the multiplicative update step (non-private) = no regret learning - suppose there are true weights you give to weather experts who are guessing the weather - everytime you make an update step, the relative entropy between the weights you have and the true weights should go down. This is an average case guarantee. the problem with fairness topics is that average means nothing. \n",
    "- after tuesday (next friday) - implement PMW where each analyst is given some fraction of the total update stpes and see if the problem still remains. different from individual setting because they'd be sharing the same synthetic database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174e2a24",
   "metadata": {},
   "source": [
    "# TO DO'S (10/17)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1fcb55",
   "metadata": {},
   "source": [
    "- [DONE] Do experiments with Bob first, see if Alice faces the same error. \n",
    "- [DONE] What is the average error of a query?\n",
    "- [DONE] What is the query with the least and most error? \n",
    "    - To figure out what things look like for each analyst and an upper/lower bound on error\n",
    "- Write code to put the functions into production for multiple tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708b108c",
   "metadata": {},
   "source": [
    "# To Do's (10/18)\n",
    "\n",
    "## Conclusions...\n",
    "We did a sanity check by reversing the order of Alice and Bob. \n",
    "\n",
    "There are mechanisms that are very specific to types of queries. H-trees are good for range queries. PMW could be the case where that PMW is good for some class of queries. We've proved that it's not\n",
    "\n",
    "## Next\n",
    "\n",
    "Update steps matter, update steps matter but end synthetic database is also valuable. \n",
    "\n",
    "- If only the update steps matter, then if we expand these query sets to very long, they should have relatively same error as doing over the entire sequence. \n",
    "\n",
    "- If the final synthetic database is also valuable, then there should be a noticable difference \n",
    "\n",
    "**To Do:** try to make an adaptation where once you make your experiment, for some large number of timestamps, randomly choose a query: 25/25 normal, for next 950 query, pick one on random and ask it repeatedly\n",
    "\n",
    "we want to see the average error from queries as time goes on. we will dilute the effect of the update steps. you should know which analysts it's from. \n",
    "\n",
    "Alice asks queries, bob asks queries. After they've asked their 25 each. Flip a coin. If heads, alice asks her queries at random. If tails, bob asks her queries at random. we want to see the effects of answering their queries on the synthetic database. In the case where we ask incompatible workloads, we saw there was the difference. do this once for each for the four queries, loook at the average error. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ec6b5d",
   "metadata": {},
   "source": [
    "# Randomly Stretched Workloads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ba5e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandomQuery(workload):\n",
    "    \"\"\"\n",
    "    Gets random query from a workload.\n",
    "    \"\"\"\n",
    "    return workload[np.random.randint(0, workload.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b142bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 1\n",
    "analysts = ['Alice', 'Bob']\n",
    "randomAnalyst=analysts[np.random.randint(0, 2)]\n",
    "workloads = {'Alice': s1alice_q, 'Bob': s1bob_q}\n",
    "random_query = getRandomQuery(workloads[randomAnalyst])\n",
    "print(f'{randomAnalyst=}')\n",
    "print(f'random_query={list(random_query)}')\n",
    "\n",
    "s1combined = pmw2(workload=np.vstack((s1alice_q, s1bob_q, np.array([getRandomQuery(workloads[randomAnalyst]) for i in range(950)]))), \n",
    "                  x=x_small, eps=2, T=40, k=10,  \n",
    "                  analyst_labels=['Alice'] * 25 + ['Bob'] * 25 + [randomAnalyst] * 950, \n",
    "                  to_return='pd', \n",
    "                  show_plot=True, show_messages=False, show_failure_step=False)\n",
    "\n",
    "print(f\"Alice's avg error = {round(s1combined[s1combined.analyst=='Alice'].real_ans.mean(), 2)}\")\n",
    "print(f\"Bob's avg error = {round(s1combined[s1combined.analyst=='Bob'].real_ans.mean(), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9810f376",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14636139",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_small/sum(x_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d9403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 2\n",
    "randomAnalyst=analysts[np.random.randint(0, 2)]\n",
    "print(f'{randomAnalyst=}')\n",
    "print(f'random_query={list(random_query)}')\n",
    "s2combined = pmw2(workload=np.vstack((s2alice_q, s2bob_q, np.array([random_query for i in range(950)]))), \n",
    "                  x=x_small, eps=2, T=40, k=10, \n",
    "                  analyst_labels=['Alice'] * 25 + ['Bob'] * 25 + [randomAnalyst] * 950, \n",
    "                  to_return='pd', \n",
    "                  show_plot=True, show_messages=False, show_failure_step=False)\n",
    "\n",
    "print(f\"Alice's avg error = {round(s2combined[s2combined.analyst=='Alice'].real_ans.mean(), 2)}\")\n",
    "print(f\"Bob's avg error = {round(s2combined[s2combined.analyst=='Bob'].real_ans.mean(), 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167dd5c5",
   "metadata": {},
   "source": [
    "Interesting. When Bob's queries are stretched really far, he has less error than Alice. When Alice's queries are stretched really far, she has more error than Bob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61910dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 3\n",
    "randomAnalyst=analysts[np.random.randint(0, 2)]\n",
    "print(f'{randomAnalyst=}')\n",
    "print(f'random_query={list(random_query)}')\n",
    "s3combined = pmw2(workload=np.vstack((s3alice_q, s3bob_q, np.array([random_query for i in range(930)]))),\n",
    "                  x=x_small, eps=2, T=40, k=10, \n",
    "                  analyst_labels=['Alice'] * 36 + ['Bob'] * 36 + [randomAnalyst] * 930, \n",
    "                  to_return='pd', \n",
    "                  show_plot=True, show_messages=False, show_failure_step=False)\n",
    "\n",
    "print(f\"Alice's avg error = {round(s3combined[s3combined.analyst=='Alice'].real_ans.mean(), 2)}\")\n",
    "print(f\"Bob's avg error = {round(s3combined[s3combined.analyst=='Bob'].real_ans.mean(), 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128a3a09",
   "metadata": {},
   "source": [
    "Alice = all range\n",
    "\n",
    "Bob = singleton\n",
    "\n",
    "Alice has substantially more error than (.5 vs .11) Bob when her query is stretched far.\n",
    "\n",
    "Bob only has a little bit more error (.49 vs .43) than Alice when his query is stretched far.\n",
    "\n",
    "Perhaps all range queries are more susceptible to error on synthetic databases than singleton queries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02ad2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 4\n",
    "randomAnalyst=analysts[np.random.randint(0, 2)]\n",
    "print(f'{randomAnalyst=}')\n",
    "print(f'random_query={list(random_query)}')\n",
    "s4combined = pmw2(workload=np.vstack((s4alice_q, s4bob_q, np.array([random_query for i in range(950)]))),\n",
    "                  x=x_small, eps=2, T=40, k=10, \n",
    "                  analyst_labels=['Alice'] * 25 + ['Bob'] * 25 + [randomAnalyst] * 950, \n",
    "                  to_return='pd', \n",
    "                  show_plot=True, show_messages=False, show_failure_step=False)\n",
    "\n",
    "print(f\"Alice's avg error = {round(s4combined[s4combined.analyst=='Alice'].real_ans.mean(), 3)}\")\n",
    "print(f\"Bob's avg error = {round(s4combined[s4combined.analyst=='Bob'].real_ans.mean(), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1acfc8",
   "metadata": {},
   "source": [
    "Their errors are about the same, even when one of the analysts has their queries stretched really far out. Very interesting. This means that the synthetic database is doing a pretty good job. \n",
    "\n",
    "Moreover, the analyst that has their query stretched out actually ends up with less error than the analyst who didn't have their query stretched out. (0.505 > 0.5). I wonder why this is. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff92d70",
   "metadata": {},
   "source": [
    "# 10/26 Notes\n",
    "- Do a new random query for all of the 950 queries. If too slow, then copy the entire workload over many times.\n",
    "- Goal: show that very simple mechanisms don't have this bad behavior. \n",
    "\n",
    "### Cache and Reuse\n",
    "- Algorithm.\n",
    "    - For the first k queries that analysts ask, answer those queries using a constant fraction of the privacy budget. Once that's done, if someone else asks those same queries, you can output the answer that you already used. \n",
    "    - Privacy budget is split between Bob and Alice. \n",
    "        - What would've been null before is no longer null because Bob can piggy back off of Alice's answers. \n",
    "        - In the individual setting, they have 1 privacy budget. In the joint setting, they each have 1 privacy budget. Alice can't eat into Bob's privacy budget. They own their own resources, but they can collaborate s.t. no one is worse off. \n",
    "    - After you use all the privacy budget, you respond with null if it's a query that you haven't seen before. \n",
    "\n",
    "- What to look for: \n",
    "    - With the same settings, show that joint version has less error than individual error. It won't fail the sharing incentive. Measure this in both total error and total number of queries answers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdca8c2",
   "metadata": {},
   "source": [
    "Psuedo code: \n",
    "- If k doesn't equal 0\n",
    "    - answer the query using laplace mechanism\n",
    "    - calculate error \n",
    "    - append to error list\n",
    "    - decrement k\n",
    "- If k equals 0\n",
    "    - append null to the error list\n",
    "    - return error list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c2fcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = np.random.randint(2, size=(11,8))[0] \n",
    "storage = {}\n",
    "\n",
    "def cache(query, storage, ans, error):\n",
    "    \"\"\"caches query into a dictionary with values of (ans, error)\"\"\"\n",
    "    storage[np.array2string(query)] = (ans, error)\n",
    "    return storage\n",
    "    \n",
    "def is_reusable(query, storage):\n",
    "    \"\"\"returns whether or not a query is in a strategy matrix \n",
    "    (cache)\"\"\"\n",
    "    return np.array2string(query) in storage\n",
    "\n",
    "def reuse(query, storage):\n",
    "    \"\"\"returns tuple with (query answer, error) stored in \n",
    "    a storage dictionary\"\"\"\n",
    "    return storage[np.array2string(query)]\n",
    "    \n",
    "\n",
    "cache(query, storage, 0.5, 0.5)\n",
    "is_reusable(query, storage)\n",
    "reuse(query, storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d2030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_and_reuse(workload, x, eps=0.01, k=0, analyst_labels=[]):\n",
    "    \"\"\"\n",
    "    Takes in workload, database, eps (privacy budget), k (number of total update steps PER ANALYST). \n",
    "    \n",
    "    Returns list of error per query.\n",
    "    \"\"\"\n",
    "    budgets = {}\n",
    "    for analyst in list(set(analyst_labels)): \n",
    "        budgets[analyst] = k # each analyst starts with k update stepss\n",
    "    \n",
    "    error_list = []\n",
    "    ans_list = []\n",
    "    updated_list = []\n",
    "    used_cache_list = []\n",
    "    \n",
    "    n = x_small.sum()\n",
    "    x_norm = x_small/sum(x_small)\n",
    "    storage = {}\n",
    "    for i, query in enumerate(workload): \n",
    "        analyst = analyst_labels[i]\n",
    "        if is_reusable(query, storage): # this analyst' query has been asked before and can be reused\n",
    "            noisy_ans, abs_error = reuse(query, storage)\n",
    "            \n",
    "            error_list.append(abs_error)\n",
    "            ans_list.append(noisy_ans)\n",
    "            updated_list.append(False)\n",
    "            used_cache_list.append(True)\n",
    "        elif budgets[analyst] != 0: # this analyst still has update steps left\n",
    "            noise = np.random.laplace(0, k/(n * eps), 1)[0]\n",
    "            noisy_ans = (np.dot(query, x_norm)) + noise\n",
    "            true_ans = np.matmul(query, x_norm)\n",
    "            abs_error = np.abs(noisy_ans - true_ans)\n",
    "            error_list.append(abs_error)\n",
    "            budgets[analyst] -= 1\n",
    "            storage = cache(query, storage, noisy_ans, abs_error)\n",
    "            \n",
    "            updated_list.append(True)\n",
    "            ans_list.append(noisy_ans)\n",
    "            used_cache_list.append(False)\n",
    "        elif budgets[analyst] == 0: # this analyst has run out of update steps\n",
    "            error_list.append(None)\n",
    "            ans_list.append(None)\n",
    "            updated_list.append(False)\n",
    "            used_cache_list.append(False)\n",
    "    d = {'queries': workload.tolist(), \n",
    "        'abs_error': error_list,\n",
    "        'ans': ans_list,\n",
    "        'updated': updated_list,\n",
    "        'used_cache': used_cache_list,\n",
    "        #'abs_error': abs_error,               \n",
    "        #'rel_error': rel_error,\n",
    "        #'synthetic database': x_list,\n",
    "        'analyst': analyst_labels,\n",
    "        #'d_t_hat': d_t_hat_list, \n",
    "    }\n",
    "    test_data = pd.DataFrame(data=d)\n",
    "    test_data = test_data.round(3)\n",
    "    test_data['isNa'] = np.where(test_data.abs_error.isnull(), True, False)\n",
    "    return test_data\n",
    "\n",
    "random_workload = np.random.randint(2, size=(11,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58882bd1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cache_experiment_s1(trials, function='reuse'):\n",
    "    \"\"\"scenario 1\"\"\"\n",
    "    num_q_unanswered = dict.fromkeys(['alice_joint', 'bob_joint', 'alice_ind', 'bob_ind'], 0)\n",
    "    abs_error_dict = dict.fromkeys(['alice_joint', 'bob_joint', 'alice_ind', 'bob_ind'], 0)\n",
    "\n",
    "    for i in range(trials):\n",
    "        s1random_array = np.random.randint(2, size=(25,4))\n",
    "        s1alice_q = np.hstack((s1random_array, s1zero_array))\n",
    "        s1bob_q = np.hstack((s1zero_array, s1random_array))\n",
    "        \n",
    "        if function=='reuse':\n",
    "            s1_cr_ab = cache_and_reuse(np.vstack((s1alice_q, s1bob_q)), x_small, eps=2, k=10, analyst_labels=['Alice'] * 25 + ['Bob'] * 25)\n",
    "        else:\n",
    "            s1_cr_ab = cache_and_reconstruct(np.vstack((s1alice_q, s1bob_q)), x_small, eps=2, k=10, analyst_labels=['Alice'] * 25 + ['Bob'] * 25)\n",
    "            \n",
    "        num_q_unanswered['alice_joint'] += (~s1_cr_ab[s1_cr_ab.analyst=='Alice'].isNa).sum()\n",
    "        num_q_unanswered['bob_joint'] += (~s1_cr_ab[s1_cr_ab.analyst=='Bob'].isNa).sum()\n",
    "        abs_error_dict['alice_joint'] += s1_cr_ab[s1_cr_ab.analyst=='Alice'].abs_error.sum()\n",
    "        abs_error_dict['bob_joint'] += s1_cr_ab[s1_cr_ab.analyst=='Bob'].abs_error.sum()\n",
    "\n",
    "        if function=='reuse':\n",
    "            s1_cr_a = cache_and_reuse(s1alice_q, x_small, eps=2, k=10, analyst_labels=['Alice'] * 25)\n",
    "        else: \n",
    "            s1_cr_a = cache_and_reconstruct(s1alice_q, x_small, eps=2, k=10, analyst_labels=['Alice'] * 25)\n",
    "\n",
    "        num_q_unanswered['alice_ind'] += (~s1_cr_a.isNa).sum()\n",
    "        abs_error_dict['alice_ind'] += s1_cr_a.abs_error.sum()\n",
    "\n",
    "        if function=='reuse':\n",
    "            s1_cr_b = cache_and_reuse(s1bob_q, x_small, eps=2, k=10, analyst_labels=['Bob'] * 25)\n",
    "        else: \n",
    "            s1_cr_b = cache_and_reconstruct(s1bob_q, x_small, eps=2, k=10, analyst_labels=['Bob'] * 25)\n",
    "        num_q_unanswered['bob_ind'] += (~s1_cr_b.isNa).sum()\n",
    "        abs_error_dict['bob_ind'] += s1_cr_b.abs_error.sum()\n",
    "\n",
    "\n",
    "    avg_q_ans = {k: v / trials for k, v in num_q_unanswered.items()}\n",
    "    avg_abs_error = {k: round(v / trials, 2) for k, v in abs_error_dict.items()}\n",
    "\n",
    "    #visualization\n",
    "    display(pd.DataFrame([avg_abs_error, avg_q_ans], index=['Total Absolute Error', '# Queries Answered']))\n",
    "\n",
    "cache_experiment_s1(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd529308",
   "metadata": {},
   "source": [
    "Bob can answer more queries in the joint case than in the individual case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c12aff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_experiment_s2(trials, function='reuse'):\n",
    "    num_q_unanswered = dict.fromkeys(['alice_joint', 'bob_joint', 'alice_ind', 'bob_ind'], 0)\n",
    "    abs_error_dict = dict.fromkeys(['alice_joint', 'bob_joint', 'alice_ind', 'bob_ind'], 0)\n",
    "\n",
    "    for i in range(trials):\n",
    "        s2alice_q = np.hstack((np.random.randint(2, size=(25,7)), np.zeros((25,1))))\n",
    "        s2bob_q = np.random.randint(2, size=(25,8))\n",
    "\n",
    "        if function=='reuse':\n",
    "            s2_cr_ab = cache_and_reuse(np.vstack((s2alice_q, s2bob_q)), x_small, eps=2, k=10, analyst_labels=['Alice'] * 25 + ['Bob'] * 25)\n",
    "        else: \n",
    "            s2_cr_ab = cache_and_reconstruct(np.vstack((s2alice_q, s2bob_q)), x_small, eps=2, k=10, analyst_labels=['Alice'] * 25 + ['Bob'] * 25)\n",
    "        \n",
    "        num_q_unanswered['alice_joint'] += (~s2_cr_ab[s2_cr_ab.analyst=='Alice'].isNa).sum()\n",
    "        num_q_unanswered['bob_joint'] += (~s2_cr_ab[s2_cr_ab.analyst=='Bob'].isNa).sum()\n",
    "        abs_error_dict['alice_joint'] += s2_cr_ab[s2_cr_ab.analyst=='Alice'].abs_error.sum()\n",
    "        abs_error_dict['bob_joint'] += s2_cr_ab[s2_cr_ab.analyst=='Bob'].abs_error.sum()\n",
    "        \n",
    "        if function=='reuse':\n",
    "            s2_cr_a = cache_and_reuse(s2alice_q, x_small, eps=2, k=10, analyst_labels=['Alice'] * 25)\n",
    "        else: \n",
    "            s2_cr_a = cache_and_reconstruct(s2alice_q, x_small, eps=2, k=10, analyst_labels=['Alice'] * 25)\n",
    "        num_q_unanswered['alice_ind'] += (~s2_cr_a.isNa).sum()\n",
    "        abs_error_dict['alice_ind'] += s2_cr_a.abs_error.sum()\n",
    "\n",
    "        if function=='reuse':\n",
    "            s2_cr_b = cache_and_reuse(s2bob_q, x_small, eps=2, k=10, analyst_labels=['Bob'] * 25)\n",
    "        else: \n",
    "            s2_cr_b = cache_and_reconstruct(s2bob_q, x_small, eps=2, k=10, analyst_labels=['Bob'] * 25)\n",
    "        num_q_unanswered['bob_ind'] += (~s2_cr_b.isNa).sum()\n",
    "        abs_error_dict['bob_ind'] += s2_cr_b.abs_error.sum()\n",
    "\n",
    "\n",
    "    avg_q_ans = {k: v / trials for k, v in num_q_unanswered.items()}\n",
    "    avg_abs_error = {k: round(v / trials, 2) for k, v in abs_error_dict.items()}\n",
    "\n",
    "    #visualization\n",
    "    display(pd.DataFrame([avg_abs_error, avg_q_ans], index=['Total Absolute Error', '# Queries Answered']))\n",
    "\n",
    "cache_experiment_s2(100, function='reuse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67967352",
   "metadata": {},
   "source": [
    "Bob is able to answer slightly less queries in the independent case than in the joint case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94628cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let Alice be the singleton asker, and Bob be the all range asker in this case: \n",
    "\n",
    "def cache_experiment_s3(trials, function='reuse'):\n",
    "    num_q_unanswered = dict.fromkeys(['alice_joint', 'bob_joint', 'alice_ind', 'bob_ind'], 0)\n",
    "    abs_error_dict = dict.fromkeys(['alice_joint', 'bob_joint', 'alice_ind', 'bob_ind'], 0)\n",
    "\n",
    "    for i in range(trials):\n",
    "        lst = [[0] * 8 for i in range(36)]\n",
    "        for i in range(len(lst)):\n",
    "            lst[i][np.random.randint(0, 8)] = 1\n",
    "        s3alice_q = np.array(lst)\n",
    "        s3bob_q = AllRange(8).dense_matrix()\n",
    "        if function=='reuse':\n",
    "            s3_cr_ab = cache_and_reuse(np.vstack((s3alice_q, s3bob_q)), x_small, eps=2, k=10, analyst_labels=['Alice'] * 36 + ['Bob'] * 36)\n",
    "        else: \n",
    "            s3_cr_ab = cache_and_reconstruct(np.vstack((s3alice_q, s3bob_q)), x_small, eps=2, k=10, analyst_labels=['Alice'] * 36 + ['Bob'] * 36)\n",
    "\n",
    "        num_q_unanswered['alice_joint'] += (~s3_cr_ab[s3_cr_ab.analyst=='Alice'].isNa).sum()\n",
    "        num_q_unanswered['bob_joint'] += (~s3_cr_ab[s3_cr_ab.analyst=='Bob'].isNa).sum()\n",
    "        abs_error_dict['alice_joint'] += s3_cr_ab[s3_cr_ab.analyst=='Alice'].abs_error.sum()\n",
    "        abs_error_dict['bob_joint'] += s3_cr_ab[s3_cr_ab.analyst=='Bob'].abs_error.sum()\n",
    "\n",
    "        if function=='reuse':\n",
    "            s3_cr_a = cache_and_reuse(s3alice_q, x_small, eps=2, k=10, analyst_labels=['Alice'] * 36)\n",
    "        else: \n",
    "            s3_cr_a = cache_and_reconstruct(s3alice_q, x_small, eps=2, k=10, analyst_labels=['Alice'] * 36)\n",
    "\n",
    "        num_q_unanswered['alice_ind'] += (~s3_cr_a.isNa).sum()\n",
    "        abs_error_dict['alice_ind'] += s3_cr_a.abs_error.sum()\n",
    "\n",
    "        if function=='reuse':\n",
    "            s3_cr_b = cache_and_reuse(s3bob_q, x_small, eps=2, k=10, analyst_labels=['Bob'] * 36)\n",
    "        else: \n",
    "            s3_cr_b = cache_and_reconstruct(s3bob_q, x_small, eps=2, k=10, analyst_labels=['Bob'] * 36)\n",
    "\n",
    "        num_q_unanswered['bob_ind'] += (~s3_cr_b.isNa).sum()\n",
    "        abs_error_dict['bob_ind'] += s3_cr_b.abs_error.sum()\n",
    "\n",
    "\n",
    "    avg_q_ans = {k: v / trials for k, v in num_q_unanswered.items()}\n",
    "    avg_abs_error = {k: round(v / trials, 2) for k, v in abs_error_dict.items()}\n",
    "\n",
    "    #visualization\n",
    "    display(pd.DataFrame([avg_abs_error, avg_q_ans], index=['Total Absolute Error', '# Queries Answered']))\n",
    "\n",
    "cache_experiment_s3(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2d6617",
   "metadata": {},
   "source": [
    "Bob can ask 10 queries using the update steps and 8 from reusing Alice's singletons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aa969d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_experiment_s4(trials, function='reuse'):\n",
    "    num_q_unanswered = dict.fromkeys(['alice_joint', 'bob_joint', 'alice_ind', 'bob_ind'], 0)\n",
    "    abs_error_dict = dict.fromkeys(['alice_joint', 'bob_joint', 'alice_ind', 'bob_ind'], 0)\n",
    "\n",
    "    for i in range(trials):\n",
    "        s4alice_q = np.random.randint(2, size=(25,8))\n",
    "        s4bob_q = s4alice_q\n",
    "\n",
    "        if function=='reuse':\n",
    "            s4_cr_ab = cache_and_reuse(np.vstack((s4alice_q, s4bob_q)), x_small, eps=2, k=10, analyst_labels=['Alice'] * 25 + ['Bob'] * 25)\n",
    "        else: \n",
    "            s4_cr_ab = cache_and_reconstruct(np.vstack((s4alice_q, s4bob_q)), x_small, eps=2, k=10, analyst_labels=['Alice'] * 25 + ['Bob'] * 25)\n",
    "\n",
    "        num_q_unanswered['alice_joint'] += (~s4_cr_ab[s4_cr_ab.analyst=='Alice'].isNa).sum()\n",
    "        num_q_unanswered['bob_joint'] += (~s4_cr_ab[s4_cr_ab.analyst=='Bob'].isNa).sum()\n",
    "        abs_error_dict['alice_joint'] += s4_cr_ab[s4_cr_ab.analyst=='Alice'].abs_error.sum()\n",
    "        abs_error_dict['bob_joint'] += s4_cr_ab[s4_cr_ab.analyst=='Bob'].abs_error.sum()\n",
    "\n",
    "        if function=='reuse':\n",
    "            s4_cr_a = cache_and_reuse(s4alice_q, x_small, eps=2, k=10, analyst_labels=['Alice'] * 25)\n",
    "        else: \n",
    "            s4_cr_a = cache_and_reconstruct(s4alice_q, x_small, eps=2, k=10, analyst_labels=['Alice'] * 25)\n",
    "\n",
    "        num_q_unanswered['alice_ind'] += (~s4_cr_a.isNa).sum()\n",
    "        abs_error_dict['alice_ind'] += s4_cr_a.abs_error.sum()\n",
    "\n",
    "        if function=='reuse':\n",
    "            s4_cr_b = cache_and_reuse(s4bob_q, x_small, eps=2, k=10, analyst_labels=['Bob'] * 25)\n",
    "        else:\n",
    "            s4_cr_b = cache_and_reconstruct(s4bob_q, x_small, eps=2, k=10, analyst_labels=['Bob'] * 25)\n",
    "\n",
    "        num_q_unanswered['bob_ind'] += (~s4_cr_b.isNa).sum()\n",
    "        abs_error_dict['bob_ind'] += s4_cr_b.abs_error.sum()\n",
    "\n",
    "\n",
    "    avg_q_ans = {k: v / trials for k, v in num_q_unanswered.items()}\n",
    "    avg_abs_error = {k: round(v / trials, 2) for k, v in abs_error_dict.items()}\n",
    "\n",
    "    #visualization\n",
    "    display(pd.DataFrame([avg_abs_error, avg_q_ans], index=['Total Absolute Error', '# Queries Answered']))\n",
    "\n",
    "cache_experiment_s4(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1db800",
   "metadata": {},
   "source": [
    "Bob can ask exactly double because he is able to conserve his own update steps by using the query answers that Alice answered for him. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d31f19b",
   "metadata": {},
   "source": [
    "# To-do's (11/9): \n",
    "- For generating workloads, don't allow repeated queries to be asked in a workload.\n",
    "- Implement average error. \n",
    "- Implement the number of times we cannot answer the query\n",
    "- Try to expand this to cache and reconstruct - essentially replace reuse with reconstruct. \n",
    "\n",
    "Reconstruction step: \n",
    "\n",
    "reconstruction - i don't have this exact query, but the sum of queries i already have might be the answer you are looking for. \n",
    "\n",
    "Reconstruction step is already pre-coded. There is a function in the matrix mechanism files that is the expected error of a workload. Store your cache in matrix form. takes a workload, strategy A, and an epsilon, and gives you an expected error. \n",
    "\n",
    "Workload would be single query\n",
    "\n",
    "Strategy of all the queries that have been saved in the cache\n",
    "\n",
    "eps you use for the function = n / k * epsilon, where n = # of queries in the strategy matrix, k = is the total number of update steps across all analysts. (take a look at the hdmm paper if you still want to learn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113aa760",
   "metadata": {},
   "source": [
    "### Nov 12 Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0897bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1random_array = np.random.randint(2, size=(25,4))\n",
    "s1alice_q = np.hstack((s1random_array, s1zero_array))\n",
    "\n",
    "print(s1alice_q[0:1])\n",
    "print(s1alice_q)\n",
    "\n",
    "print(expected_error(s1alice_q, s1alice_q[0:1], eps = 1))\n",
    "print(expected_error(s1alice_q, s1alice_q[0:1], eps = 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d14695",
   "metadata": {},
   "source": [
    "Realistically the error should be zero for this query, because the query is literally drawn from the first query in the strategy matrix. Not sure why the error is a positive number. \n",
    "\n",
    "However, the behavior of error decreasing when epsilon approaches infinity is accurate in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ad76a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing on separate parts of the array: \n",
    "expected_error(s1bob_q[0:1], s1alice_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54906555",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 1, 1]])\n",
    "b = np.array([[1, 1, 1]])\n",
    "np.concatenate((a, b), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8321243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims(a, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a596b30b",
   "metadata": {},
   "source": [
    "eps you use for the function = n / k * epsilon, where n = # of queries in the strategy matrix, k = is the total number of update steps across all analysts. (take a look at the hdmm paper if you still want to learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b8ef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_strategy(query, strategy):\n",
    "    \"\"\"Append query to the end fo the strategy matrix\"\"\"\n",
    "    return np.concatenate((strategy, query), axis = 0)\n",
    "\n",
    "def cache_and_reconstruct(workload, x, eps=0.01, k=0, analyst_labels=[]):\n",
    "    \"\"\"\n",
    "    Takes in workload, database, eps (privacy budget), k (number of total update steps PER ANALYST). \n",
    "    \n",
    "    Returns list of error per query.\n",
    "    \"\"\"\n",
    "    budgets = {}\n",
    "    for analyst in list(set(analyst_labels)): \n",
    "        budgets[analyst] = k # each analyst starts with k update steps\n",
    "    \n",
    "    numAnalysts = len(budgets)\n",
    "    error_list = []\n",
    "    updated_list = []\n",
    "    used_reconstruct_list = []\n",
    "    \n",
    "    n = x_small.sum()\n",
    "    x_norm = x_small/sum(x_small) # normalize database\n",
    "    strategy = workload[0 : 1]\n",
    "    for i, query in enumerate(workload): \n",
    "        query = np.expand_dims(query, axis = 0)\n",
    "        analyst = analyst_labels[i]\n",
    "        \n",
    "        if budgets[analyst] != 0: # this analyst still has update steps left\n",
    "            noise = np.random.laplace(0, (k * numAnalysts) / (n * eps), 1)[0]\n",
    "            noisy_ans = (np.dot(query, x_norm)) + noise\n",
    "            true_ans = np.matmul(query, x_norm)\n",
    "            error_list.append(np.abs(noisy_ans - true_ans)[0] * n) \n",
    "            budgets[analyst] -= 1 \n",
    "            if i != 0:\n",
    "                strategy = add_to_strategy(query, strategy)\n",
    "            \n",
    "            updated_list.append(True)\n",
    "            used_reconstruct_list.append(False)\n",
    "            \n",
    "        elif strategy_supports_workload(EkteloMatrix(query), EkteloMatrix(strategy)): # how to convert numpy array to ektelo matrix https://github.com/yikai-wu/Multi-Analyst-DP/blob/fadc7ac1d20199e8b31914f44323e51a05ed072d/src/hdmm/matrix.py#L34\n",
    "            \n",
    "            abs_error = expected_error(query, strategy, eps = len(strategy) / (k * numAnalysts) * eps) # do i mult by 100\n",
    "            \n",
    "            error_list.append(abs_error)\n",
    "            updated_list.append(False)\n",
    "            used_reconstruct_list.append(True) \n",
    "            \n",
    "        elif budgets[analyst] == 0: # this analyst has run out of update steps\n",
    "            error_list.append(None)\n",
    "            updated_list.append(False)\n",
    "            used_reconstruct_list.append(False)\n",
    "        \n",
    "            \n",
    "    d = {'queries': workload.tolist(), \n",
    "        'abs_error': error_list,\n",
    "        'updated': updated_list,\n",
    "        'used_reconstruct': used_reconstruct_list,\n",
    "        'analyst': analyst_labels,\n",
    "    }\n",
    "    test_data = pd.DataFrame(data=d)\n",
    "    test_data = test_data.round(3)\n",
    "    test_data['isNa'] = np.where(test_data.abs_error.isnull(), True, False)\n",
    "    return test_data\n",
    "\n",
    "random_workload = np.random.randint(2, size=(11,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee85ca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_and_reuse(np.vstack((s1alice_q, s1bob_q)), x_small, eps=2, k=10, \n",
    "                      analyst_labels=['Alice'] * 25 + ['Bob'] * 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ab2088",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s1random_array = np.random.randint(2, size=(25,4))\n",
    "s1alice_q = np.hstack((s1random_array, s1zero_array))\n",
    "s1bob_q = np.hstack((s1zero_array, s1random_array))\n",
    "\n",
    "cache_and_reconstruct(np.vstack((s1alice_q, s1bob_q)), x_small, eps=2, k=10, \n",
    "                      analyst_labels=['Alice'] * 25 + ['Bob'] * 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e2f1c6",
   "metadata": {},
   "source": [
    "# Long-term To-do's (11/9):\n",
    "Results: \n",
    "- Look at Yikais papers to see how to structure the results of your experiments for the papers.\n",
    "- Toy results (shown in the definition), larger evaluations (testing efficacy on larger experiments on the cluster. Datasets like this dont work. Make a stochastic process for generating these sets) \n",
    "- Try to get these done in Janurary. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b520d0",
   "metadata": {},
   "source": [
    "# 11/12 To-do's: \n",
    "- [done] Fix cache and reconstruct cache epsilon step\n",
    "- [done] Run cache and reconstruct on all settings\n",
    "- [done] New implementation of PMW with splitting budget "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e734d37b",
   "metadata": {},
   "source": [
    "# 11/17 to do's: \n",
    "- Add old PMW as well\n",
    "- call new one shared_PMW\n",
    "- Run experiments for reconstruct and shared PMW\n",
    "    - see if shared PMW meets non-interference and sharing desiderata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd0718e77e574b71e9f7991c7da6831896cfd7281e366db0dbf84de44e8d5f66e5a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
